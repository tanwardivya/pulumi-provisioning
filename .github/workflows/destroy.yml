name: Destroy Infrastructure

on:
  workflow_dispatch:
    inputs:
      stack:
        description: "Stack to destroy (test or prod)"
        required: true
        type: choice
        options:
          - test
          - prod
      confirm:
        description: 'Type "destroy" to confirm'
        required: true
        type: string

env:
  AWS_REGION: us-east-1

jobs:
  destroy:
    runs-on: ubuntu-latest
    permissions:
      id-token: write # Required for OIDC authentication
      contents: read # Required to checkout code
    environment:
      name: ${{ github.event.inputs.stack }}-destroy
    steps:
      - uses: actions/checkout@v4

      - name: Verify confirmation
        run: |
          if [ "${{ github.event.inputs.confirm }}" != "destroy" ]; then
            echo "Confirmation failed. Type 'destroy' to proceed."
            exit 1
          fi

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: "latest"

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install jq
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: Install Pulumi dependencies
        working-directory: infrastructure
        run: |
          uv venv
          source .venv/bin/activate
          uv pip install -e ".[dev]"

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          # Use appropriate role based on stack being destroyed
          # For prod: use prod role (or fallback to default)
          # For test: use test role (or fallback to default)
          role-to-assume: ${{ github.event.inputs.stack == 'prod' && secrets.AWS_PROD_ROLE_ARN || github.event.inputs.stack == 'test' && secrets.AWS_TEST_ROLE_ARN || secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Pulumi
        uses: pulumi/actions@v4
        with:
          pulumi-version: latest

      - name: Select Pulumi Stack
        working-directory: infrastructure
        run: |
          source .venv/bin/activate
          pulumi stack select ${{ github.event.inputs.stack }}
        env:
          PULUMI_ACCESS_TOKEN: ${{ secrets.PULUMI_ACCESS_TOKEN }}
          PULUMI_PYTHON_CMD: ${{ github.workspace }}/infrastructure/.venv/bin/python

      - name: Check and Cancel In-Progress Operations
        working-directory: infrastructure
        run: |
          source .venv/bin/activate
          echo "Checking for in-progress Pulumi operations..."

          # Try to get stack info - if there's a conflict, we'll see it
          # Attempt to cancel any in-progress operations
          echo "Attempting to cancel any in-progress operations..."
          if pulumi cancel --stack ${{ github.event.inputs.stack }} 2>&1; then
            echo "‚úÖ Cancelled in-progress operation"
            # Wait for cancellation to complete
            echo "Waiting 15 seconds for cancellation to complete..."
            sleep 15
          else
            echo "‚ÑπÔ∏è  No in-progress operation found (or already completed)"
          fi

          echo "‚úÖ Ready to proceed with destroy"
        env:
          PULUMI_ACCESS_TOKEN: ${{ secrets.PULUMI_ACCESS_TOKEN }}
          PULUMI_PYTHON_CMD: ${{ github.workspace }}/infrastructure/.venv/bin/python

      - name: Set Pulumi Config from GitHub Secrets
        working-directory: infrastructure
        run: |
          source .venv/bin/activate
          # Pulumi needs config to properly destroy resources
          # Set DB password if available (needed for RDS destroy)
          if [ -n "${{ secrets.DB_PASSWORD }}" ]; then
            pulumi config set --secret dbPassword "${{ secrets.DB_PASSWORD }}"
          fi
          # Set domain name if available
          if [ -n "${{ secrets.DOMAIN_NAME }}" ]; then
            pulumi config set domainName "${{ secrets.DOMAIN_NAME }}"
          fi
        env:
          PULUMI_ACCESS_TOKEN: ${{ secrets.PULUMI_ACCESS_TOKEN }}
          PULUMI_PYTHON_CMD: ${{ github.workspace }}/infrastructure/.venv/bin/python

      - name: Preview Resources to be Destroyed
        working-directory: infrastructure
        run: |
          source .venv/bin/activate
          echo "=========================================="
          echo "üìã Preview: Resources to be Destroyed"
          echo "=========================================="
          echo "Stack: ${{ github.event.inputs.stack }}"
          echo ""
          echo "This preview shows what will be destroyed:"
          echo "- EC2 instance and Elastic IP"
          echo "- RDS database instance"
          echo "- S3 bucket and all objects"
          echo "- ECR repository and all images"
          echo "- VPC, subnets, security groups, gateways"
          echo "- IAM roles and policies"
          echo "- SSM parameters (db_password, image_tag)"
          echo ""
          echo "Running Pulumi preview..."
          echo "=========================================="
          pulumi preview --stack ${{ github.event.inputs.stack }} --diff
        env:
          PULUMI_ACCESS_TOKEN: ${{ secrets.PULUMI_ACCESS_TOKEN }}
          PULUMI_PYTHON_CMD: ${{ github.workspace }}/infrastructure/.venv/bin/python

      - name: Clean up ECR Images (if repository exists)
        working-directory: infrastructure
        run: |
          source .venv/bin/activate
          echo "Cleaning up ECR images before destroy..."

          # Get ECR repository name from Pulumi stack output
          ECR_REPO_NAME=$(pulumi stack output ecr_repository_name --stack ${{ github.event.inputs.stack }} 2>/dev/null || echo "")

          if [ -n "$ECR_REPO_NAME" ] && [ "$ECR_REPO_NAME" != "null" ] && [ "$ECR_REPO_NAME" != "" ]; then
            echo "Found ECR repository: $ECR_REPO_NAME"
            echo "Deleting all images from repository..."
            
            # Delete all images (by listing all and deleting)
            IMAGE_IDS=$(aws ecr list-images \
              --repository-name "$ECR_REPO_NAME" \
              --region "${{ env.AWS_REGION }}" \
              --query 'imageIds[*]' \
              --output json 2>/dev/null || echo "[]")
            
            if [ "$IMAGE_IDS" != "[]" ] && [ -n "$IMAGE_IDS" ]; then
              echo "Deleting all images from repository..."
              echo "$IMAGE_IDS" | jq -c '.[]' | while read -r image; do
                aws ecr batch-delete-image \
                  --repository-name "$ECR_REPO_NAME" \
                  --image-ids "$image" \
                  --region "${{ env.AWS_REGION }}" 2>/dev/null || true
              done
              echo "‚úÖ ECR images cleaned up"
            else
              echo "‚ÑπÔ∏è  No images found in repository"
            fi
          else
            echo "‚ÑπÔ∏è  ECR repository not found or not accessible"
          fi
        env:
          PULUMI_ACCESS_TOKEN: ${{ secrets.PULUMI_ACCESS_TOKEN }}
          PULUMI_PYTHON_CMD: ${{ github.workspace }}/infrastructure/.venv/bin/python
          AWS_REGION: ${{ env.AWS_REGION }}

      - name: Clean up IAM Policies (if role exists)
        working-directory: infrastructure
        run: |
          source .venv/bin/activate
          echo "Cleaning up IAM policies before destroy..."

          # IAM role name pattern: {stack}-iam-role-{random} (Pulumi adds random suffix)
          # Also check for: pulumi-{stack}-ec2-role pattern
          STACK="${{ github.event.inputs.stack }}"

          echo "Searching for IAM roles matching patterns:"
          echo "  - ${STACK}-iam-role-*"
          echo "  - pulumi-${STACK}-ec2-role*"

          # Find all roles matching the pattern
          ROLE_NAMES=$(aws iam list-roles \
            --query "Roles[?starts_with(RoleName, '${STACK}-iam-role') || starts_with(RoleName, 'pulumi-${STACK}-ec2-role')].RoleName" \
            --output text 2>/dev/null || echo "")

          if [ -n "$ROLE_NAMES" ] && [ "$ROLE_NAMES" != "None" ] && [ "$ROLE_NAMES" != "" ]; then
            # Process each role found
            for IAM_ROLE_NAME in $ROLE_NAMES; do
              if [ "$IAM_ROLE_NAME" != "None" ] && [ -n "$IAM_ROLE_NAME" ] && [ "$IAM_ROLE_NAME" != "" ]; then
                echo ""
                echo "Processing IAM role: $IAM_ROLE_NAME"
                
                # Check if role exists (double-check)
                if aws iam get-role --role-name "$IAM_ROLE_NAME" >/dev/null 2>&1; then
            echo "Found IAM role: $IAM_ROLE_NAME"
            echo "Detaching policies from role..."
            
            # Detach managed policies
            MANAGED_POLICIES=$(aws iam list-attached-role-policies \
              --role-name "$IAM_ROLE_NAME" \
              --query 'AttachedPolicies[*].PolicyArn' \
              --output text 2>/dev/null || echo "")
            
            if [ -n "$MANAGED_POLICIES" ] && [ "$MANAGED_POLICIES" != "None" ] && [ "$MANAGED_POLICIES" != "" ]; then
              for policy_arn in $MANAGED_POLICIES; do
                if [ "$policy_arn" != "None" ] && [ -n "$policy_arn" ] && [ "$policy_arn" != "" ]; then
                  echo "Detaching policy: $policy_arn"
                  aws iam detach-role-policy \
                    --role-name "$IAM_ROLE_NAME" \
                    --policy-arn "$policy_arn" 2>/dev/null || true
                fi
              done
            fi
            
            # Delete inline policies
            INLINE_POLICIES=$(aws iam list-role-policies \
              --role-name "$IAM_ROLE_NAME" \
              --query 'PolicyNames[*]' \
              --output text 2>/dev/null || echo "")
            
            if [ -n "$INLINE_POLICIES" ] && [ "$INLINE_POLICIES" != "None" ] && [ "$INLINE_POLICIES" != "" ]; then
              for policy_name in $INLINE_POLICIES; do
                if [ "$policy_name" != "None" ] && [ -n "$policy_name" ] && [ "$policy_name" != "" ]; then
                  echo "Deleting inline policy: $policy_name"
                  aws iam delete-role-policy \
                    --role-name "$IAM_ROLE_NAME" \
                    --policy-name "$policy_name" 2>/dev/null || true
                fi
              done
            fi
            
            # Find and delete instance profiles associated with this role
            # Instance profile name pattern: {stack}-iam-instance-profile-{random}
            INSTANCE_PROFILES=$(aws iam list-instance-profiles-for-role \
              --role-name "$IAM_ROLE_NAME" \
              --query 'InstanceProfiles[*].InstanceProfileName' \
              --output text 2>/dev/null || echo "")
            
            if [ -n "$INSTANCE_PROFILES" ] && [ "$INSTANCE_PROFILES" != "None" ] && [ "$INSTANCE_PROFILES" != "" ]; then
              for INSTANCE_PROFILE_NAME in $INSTANCE_PROFILES; do
                if [ "$INSTANCE_PROFILE_NAME" != "None" ] && [ -n "$INSTANCE_PROFILE_NAME" ] && [ "$INSTANCE_PROFILE_NAME" != "" ]; then
                  echo "Removing role from instance profile: $INSTANCE_PROFILE_NAME"
                  aws iam remove-role-from-instance-profile \
                    --instance-profile-name "$INSTANCE_PROFILE_NAME" \
                    --role-name "$IAM_ROLE_NAME" 2>/dev/null || true
                  
                  echo "Deleting instance profile: $INSTANCE_PROFILE_NAME"
                  aws iam delete-instance-profile \
                    --instance-profile-name "$INSTANCE_PROFILE_NAME" 2>/dev/null || true
                fi
              done
            fi
            
                  echo "‚úÖ IAM policies cleaned up for role: $IAM_ROLE_NAME"
                else
                  echo "‚ÑπÔ∏è  Role not accessible: $IAM_ROLE_NAME"
                fi
              fi
            done
            echo ""
            echo "‚úÖ IAM cleanup completed for all matching roles"
          else
            echo "‚ÑπÔ∏è  No IAM roles found matching patterns (may already be deleted)"
          fi
        env:
          PULUMI_ACCESS_TOKEN: ${{ secrets.PULUMI_ACCESS_TOKEN }}
          PULUMI_PYTHON_CMD: ${{ github.workspace }}/infrastructure/.venv/bin/python
          AWS_REGION: ${{ env.AWS_REGION }}

      - name: Final Warning Before Destruction
        run: |
          echo "=========================================="
          echo "‚ö†Ô∏è  FINAL WARNING - INFRASTRUCTURE DESTRUCTION"
          echo "=========================================="
          echo "Stack: ${{ github.event.inputs.stack }}"
          echo ""
          echo "You are about to PERMANENTLY DELETE:"
          echo "  ‚ùå All EC2 instances"
          echo "  ‚ùå All RDS databases (data will be lost!)"
          echo "  ‚ùå All S3 buckets and objects"
          echo "  ‚ùå All ECR repositories and images"
          echo "  ‚ùå All VPC networking resources"
          echo "  ‚ùå All IAM roles and policies"
          echo "  ‚ùå All SSM parameters"
          echo ""
          echo "This action CANNOT be undone!"
          echo ""
          echo "Waiting 10 seconds before proceeding..."
          echo "=========================================="
          sleep 10

      - name: Pulumi Destroy
        working-directory: infrastructure
        run: |
          source .venv/bin/activate
          echo "=========================================="
          echo "üóëÔ∏è  Destroying Infrastructure"
          echo "=========================================="
          echo "Stack: ${{ github.event.inputs.stack }}"
          echo ""

          # Retry logic for update conflicts
          MAX_RETRIES=3
          RETRY_COUNT=0
          DESTROY_SUCCESS=false

          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            RETRY_COUNT=$((RETRY_COUNT + 1))
            echo "Destroy attempt $RETRY_COUNT/$MAX_RETRIES..."
            
            # Capture output to check for specific errors
            DESTROY_OUTPUT=$(pulumi destroy --yes --stack ${{ github.event.inputs.stack }} 2>&1) || {
              EXIT_CODE=$?
              
              # Check if it's an update conflict
              if echo "$DESTROY_OUTPUT" | grep -q "Another update is currently in progress"; then
                echo "‚ö†Ô∏è  Update conflict detected:"
                echo "$DESTROY_OUTPUT" | grep -A 2 "Another update"
                echo ""
                echo "Waiting 30 seconds and attempting to cancel conflicting operation..."
                sleep 30
                
                # Try to cancel the conflicting operation
                echo "Attempting to cancel conflicting operation..."
                pulumi cancel --stack ${{ github.event.inputs.stack }} 2>/dev/null || true
                sleep 15
                
                # Continue to next retry
                continue
              else
                # Other error - show output and exit
                echo "‚ùå Destroy failed:"
                echo "$DESTROY_OUTPUT"
                exit $EXIT_CODE
              fi
            }
            
            # Success
            echo "$DESTROY_OUTPUT"
            DESTROY_SUCCESS=true
            break
          done

          if [ "$DESTROY_SUCCESS" = "true" ]; then
            echo ""
            echo "=========================================="
            echo "‚úÖ Destruction Complete"
            echo "=========================================="
          else
            echo ""
            echo "=========================================="
            echo "‚ùå Destruction Failed After $MAX_RETRIES Attempts"
            echo "=========================================="
            echo "Another Pulumi operation is still in progress."
            echo ""
            echo "To resolve:"
            echo "  1. Go to Pulumi Cloud: https://app.pulumi.com"
            echo "  2. Navigate to your stack: pulumi-provisioning/${{ github.event.inputs.stack }}"
            echo "  3. Check for in-progress operations and cancel them if needed"
            echo "  4. Wait a few minutes for operations to complete"
            echo "  5. Retry the destroy workflow"
            exit 1
          fi
        env:
          PULUMI_ACCESS_TOKEN: ${{ secrets.PULUMI_ACCESS_TOKEN }}
          PULUMI_PYTHON_CMD: ${{ github.workspace }}/infrastructure/.venv/bin/python

      - name: Destruction Summary
        if: always()
        run: |
          echo "=========================================="
          if [ "${{ job.status }}" = "success" ]; then
            echo "‚úÖ Infrastructure Destruction Completed"
            echo "=========================================="
            echo "Stack: ${{ github.event.inputs.stack }}"
            echo ""
            echo "All resources have been destroyed:"
            echo "  ‚úÖ EC2 instances terminated"
            echo "  ‚úÖ RDS databases deleted"
            echo "  ‚úÖ S3 buckets deleted"
            echo "  ‚úÖ ECR repositories deleted"
            echo "  ‚úÖ VPC and networking resources deleted"
            echo "  ‚úÖ IAM roles and policies deleted"
            echo "  ‚úÖ SSM parameters deleted"
            echo ""
            echo "Note: Some resources may take a few minutes to fully delete."
            echo "Check AWS Console to verify all resources are removed."
          else
            echo "‚ùå Infrastructure Destruction Failed"
            echo "=========================================="
            echo "Stack: ${{ github.event.inputs.stack }}"
            echo ""
            echo "Some resources may not have been destroyed."
            echo "Check the logs above for errors."
            echo ""
            echo "Common issues:"
            echo "  - Another Pulumi operation in progress (update conflict)"
            echo "  - RDS final snapshot creation failed"
            echo "  - S3 bucket not empty"
            echo "  - ECR repository has images"
            echo "  - IAM role dependencies"
            echo ""
            echo "If you see 'Another update is currently in progress':"
            echo "  1. Check Pulumi Cloud for in-progress operations"
            echo "  2. Wait a few minutes for the operation to complete"
            echo "  3. Or cancel the operation manually in Pulumi Cloud"
            echo "  4. Then retry the destroy workflow"
            echo ""
            echo "You may need to manually clean up remaining resources."
          fi
          echo "=========================================="
